---
title: "Assignment 1 - Language development in autistic and neurotypical children"
output:
  pdf_document: default
  html_document: default
date: "2022-08-15"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r install packages}
pacman::p_load(tidyverse, gridExtra, loo, bayesplot, brms)
#cmdstanr
#brms
```


```{r read in data}

asd_data <- read_csv("data_clean.csv")

```



# Assignment 1  - Language development in autistic and neurotypical children

## Quick recap
Autism Spectrum Disorder is often related to language impairment. However, this phenomenon has rarely been empirically traced in detail: i) relying on actual naturalistic language production, ii) over extended periods of time.

We therefore videotaped circa 30 kids with ASD and circa 30 comparison kids (matched by linguistic performance at visit 1) for ca. 30 minutes of naturalistic interactions with a parent. We repeated the data collection 6 times per kid, with 4 months between each visit. We transcribed the data and counted: 
i) the amount of words that each kid uses in each video. Same for the parent.
ii) the amount of unique words that each kid uses in each video. Same for the parent.
iii) the amount of morphemes per utterance (Mean Length of Utterance) displayed by each child in each video. Same for the parent. 

This data is in the file you prepared in the previous class, but you can also find it here:https://www.dropbox.com/s/d6eerv6cl6eksf3/data_clean.csv?dl=0


## The structure of the assignment

We will be spending a few weeks with this assignment. In particular, we will:

Part 1) simulate data in order to better understand the model we need to build, and to better understand how much data we would have to collect to run a meaningful study (precision analysis)

Part 2) analyze our empirical data and interpret the inferential results

Part 3) use your model to predict the linguistic trajectory of new children and assess the performance of the model based on that.

As you work through these parts, you will have to produce a written document (separated from the code) answering the following questions:

Q1 - Briefly describe your simulation process, its goals, and what you have learned from the simulation. Add at least a plot showcasing the results of the simulation. Make a special note on sample size considerations: how much data do you think you will need? what else could you do to increase the precision of your estimates?

Q2 - Briefly describe the empirical data and how they compare to what you learned from the simulation (what can you learn from them?). Briefly describe your model(s) and model quality. Report the findings: how does development differ between autistic and neurotypical children (N.B. remember to report both population and individual level findings)? which additional factors should be included in the model? Add at least one plot showcasing your findings.

Q3 - Given the model(s) from Q2, how well do they predict the data? Discuss both in terms of absolute error in training vs testing; and in terms of characterizing the new kids' language development as typical or in need of support.


Below you can find more detailed instructions for each part of the assignment.

## Part 1 - Simulating data

Before we even think of analyzing the data, we should make sure we understand the problem, and we plan the analysis. To do so, we need to simulate data and analyze the simulated data (where we know the ground truth).

In particular, let's imagine we have n autistic and n neurotypical children. We are simulating their average utterance length (Mean Length of Utterance or MLU) in terms of words, starting at Visit 1 and all the way to Visit 6.
In other words, we need to define a few parameters:
- average MLU for ASD (population mean) at Visit 1 and average individual deviation from that (population standard deviation)
- average MLU for TD (population mean) at Visit 1 and average individual deviation from that (population standard deviation)
- average change in MLU by visit for ASD (population mean) and average individual deviation from that (population standard deviation)
- average change in MLU by visit for TD (population mean) and average individual deviation from that (population standard deviation)
- an error term. Errors could be due to measurement, sampling, all sorts of noise. 

Note that this makes a few assumptions: population means are exact values; change by visit is linear (the same between visit 1 and 2 as between visit 5 and 6). This is fine for the exercise. In real life research, you might want to vary the parameter values much more, relax those assumptions and assess how these things impact your inference.


We go through the literature and we settle for some values for these parameters:
- average MLU for ASD and TD: 1.5 (remember the populations are matched for linguistic ability at first visit)
- average individual variability in initial MLU for ASD 0.5; for TD 0.3 (remember ASD tends to be more heterogeneous)
- average change in MLU for ASD: 0.4; for TD 0.6 (ASD is supposed to develop less)
- average individual variability in change for ASD 0.4; for TD 0.2 (remember ASD tends to be more heterogeneous)
- error is identified as 0.2

This would mean that on average the difference between ASD and TD participants is 0 at visit 1, 0.2 at visit 2, 0.4 at visit 3, 0.6 at visit 4, 0.8 at visit 5 and 1 at visit 6.

With these values in mind, simulate data, plot the data (to check everything is alright); and set up an analysis pipeline.
Remember the usual bayesian workflow:
- define the formula
- define the prior
- prior predictive checks
- fit the model
- model quality checks: traceplots, divergences, rhat, effective samples
- model quality checks: posterior predictive checks, prior-posterior update checks
- model comparison

Once the pipeline is in place, loop through different sample sizes to assess how much data you would need to collect. N.B. for inspiration on how to set this up, check the tutorials by Kurz that are linked in the syllabus.

BONUS questions for Part 1: what if the difference between ASD and TD was 0? how big of a sample size would you need? What about different effect sizes, and different error terms.

### Preparation for the simulation
```{r Parameter setup}
# These parameters were given in the literature
n <- 30
Visit <- 6
mu_asd <- log(1.5)
sigma_asd <- log(1.5) - log(1.5-0.5)
mu_td <- log(1.5)
sigma_td <- log(1.5) - log(1.5-0.3)

# 5 variables simulated from a rnorm histogram 
# We were looking at the range of development between zero and the doubled population mean
#Trial and error
mu_visit_asd <- 0.1
sigma_visit_asd <- 0.06
mu_visit_td <- 0.18
sigma_visit_td <- 0.03
error <- 0.1

```


### Creating a tibble + simulation
```{r}
set.seed(3006)

d <- tibble(expand.grid(
  ID=seq(n),
  Diagnosis=(c('asd','td')),
  Visit=seq(Visit),
  IndivdualIntercept = NA,
  IndividualSlope = NA,
  MLU = NA))

d <- d %>% 
  mutate(ID = ifelse(Diagnosis == "asd", ID +(n*2), ID))

# simulates the intercept and slopes for each child for each diagnosis
for (i in seq(d$ID)){
    d$IndivdualIntercept[d$ID == i & d$Diagnosis == "asd"] <- rnorm(1,mu_asd,sigma_asd)
    d$IndivdualIntercept[d$ID == i & d$Diagnosis == "td"] <- rnorm(1,mu_td,sigma_td)
    d$IndividualSlope[d$ID == i & d$Diagnosis == "asd"] <- rnorm(1,mu_visit_asd,sigma_visit_asd)
    d$IndividualSlope[d$ID == i & d$Diagnosis == "td"] <- rnorm(1,mu_visit_td,sigma_visit_td)
}

# adding calculation for individual slopes
for (i in seq(nrow(d))){
  d$MLU[i] <- exp(rnorm(1,d$IndivdualIntercept[i]+d$IndividualSlope[i]*(d$Visit[i]-1),error))
}

```

### Plotting the simulation
```{r}
ggplot(d, aes(Visit, MLU, col = Diagnosis, group = ID)) + 
theme_bw() + 
geom_point() +
geom_line(alpha = 0.4)

ggsave("Simulation_redacted.jpg")

```

### Defining the model formulas
```{r}

MLU_f1 <- bf(MLU~1+Diagnosis)
MLU_f2 <- bf(MLU~0+Diagnosis+Diagnosis:Visit)
MLU_f3 <- bf(MLU~0+Diagnosis+Diagnosis:Visit+(1+Visit|ID))

```

Mean Intercept-ASD: normal(0.41,0.05)
Mean Intercept SD-ASD: normal(0,0.41)

Mean Intercept–TD: normal(0.41,0.2)
Mean Intercept SD–TD: normal(0,0.22)

Mean Visit effect–ASD: normal(0,0.1)
Mean Visit effect SD–ASD: normal(0,0.06)

Mean Visit effect–TD: normal(0,0.6)
Mean Visit effect SD: normal(0,0.03)

### Defining the priors for running the model
```{r}

p1 <- c(
  prior(normal(0,0.3),class=b,lb=0),
  prior(normal(0,1),class=Intercept),
  prior(normal(0,0.5),class=sigma))

p2 <- c(
  prior(normal(0.41,0.8),class=b,coef="Diagnosisasd"),
  prior(normal(0.41,0.5),class=b,coef="Diagnosistd"),
  prior(normal(0,0.2),class=b,coef="Diagnosisasd:Visit"),
  prior(normal(0,0.1),class=b,coef="Diagnosistd:Visit"),
  prior(normal(0,0.5),class=sigma))

p3 <- c(
  prior(normal(0.41,0.8),class=b,coef="Diagnosisasd"),
  prior(normal(0.41,0.5),class=b,coef="Diagnosistd"),
  prior(normal(0,0.2),class=b,coef="Diagnosisasd:Visit"),
  prior(normal(0,0.1),class=b,coef="Diagnosistd:Visit"),
  prior(normal(0,0.4),class=sd,coef=Intercept,group=ID),
  prior(normal(0,0.3),class=sd,coef=Visit,group=ID),
  prior(normal(1,0.5),class=sigma),
  prior(lkj(1),class="cor"))

```


### Modeling only the priors
```{r}
m1_prior <- 
  brm(
    MLU_f1,
    data = d,
    prior = p1,
    family = lognormal,
    sample_prior="only",
    backend = "cmdstanr",
    file = "a1_m1_red1",
    warmup = 1000,
    iter = 4000,
    chains = 2,
    cores = 2,
    control = list(
      adapt_delta = 0.99,
      max_treedepth = 20
    )
  )

m2_prior <- 
  brm(
    MLU_f2,
    data = d,
    prior = p2,
    family = lognormal,
    sample_prior="only",
    backend = "cmdstanr",
    file = "a1_m2_red1",
    warmup = 1000,
    iter = 4000,
    chains = 2,
    cores = 2,
    control = list(
      adapt_delta = 0.99,
      max_treedepth = 20
    )
  )

m3_prior <- 
  brm(
    MLU_f3,
    data = d,
    prior = p3,
    family = lognormal,
    sample_prior="only",
    backend = "cmdstanr",
    file = "a1_m2_red1",
    warmup = 1000,
    iter = 4000,
    chains = 2,
    cores = 2,
    control = list(
      adapt_delta = 0.99,
      max_treedepth = 20
    )
  )

```


### Visualizing the priors with a prior predictive check
```{r}
pp_pm1 <- pp_check(m1_prior, ndraws = 100) + labs(title = "Model 1 - prior") + xlim(-1, 10)
pp_pm2 <- pp_check(m2_prior, ndraws = 100) + labs(title = "Model 2 - prior") + xlim(-1, 10)
pp_pm3 <- pp_check(m3_prior, ndraws = 100) + labs(title = "Model 3 - prior") + xlim(-1, 10)

prior_save <- grid.arrange(pp_pm1, pp_pm2, pp_pm3, ncol=2, top = "Prior predictive check")
ggsave("prior_save.jpg", prior_save)

```

### Running the models with the priors on our simulated data
```{r warning=FALSE}
MLU_m1 <-
  brm(
    MLU_f1,
    data = d,
    save_pars = save_pars(all = TRUE),
    family = lognormal,
    prior = p1,
    file = "MLU_m1_red1",
    sample_prior = T,
    iter = 4000, 
    warmup = 1000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4),
    control = list(
      adapt_delta = 0.99,
      max_treedepth = 15 ))

MLU_m2 <-
  brm(
    MLU_f2,
    data = d,
    save_pars = save_pars(all = TRUE),
    family = lognormal,
    prior = p2,
    file = "MLU_m2_red1",
    sample_prior = T,
    iter = 4000, 
    warmup = 1000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4),
    control = list(
      adapt_delta = 0.99,
      max_treedepth = 15 ))

MLU_m3_1 <-
  brm(
    MLU_f3,
    data = d,
    family = lognormal,
    prior = p3,
    file = "MLU_m3_try",
    sample_prior = T,
    iter = 4000, 
    warmup = 1000,
    cores = 2,
    chains = 2,
    backend = "cmdstanr",
    threads = threading(4),
    control = list(
      adapt_delta = 0.99,
      max_treedepth = 15 ))



```

### Visualizing the prior posterior update checks
```{r}
pp_posm1 <- brms::pp_check(MLU_m1, ndraws = 100) + labs(title = "Model 1 - posterior") + xlim(-1, 8)
pp_posm2 <- brms::pp_check(MLU_m2, ndraws = 100) + labs(title = "Model 2 - posterior") + xlim(-1, 8)
pp_posm3 <- brms::pp_check(MLU_m3_1, ndraws = 100) + labs(title = "Model 3 - posterior") + xlim(-1, 8)

posterior_pp <- grid.arrange(pp_posm1, pp_posm2, pp_posm3, ncol = 2, top = "Prior posterior predictive check")
ggsave("posterior_pp.png", posterior_pp)


```
### Prior-posterior update plots for model 1
```{r}
#Converts objects to the draws_df format, which are tibble data frames
Posterior_m1 <- as_draws_df(MLU_m1)

#prior-posterior update plot for the intercept:
m1p1 <- ggplot(Posterior_m1) +
  geom_density(aes(prior_Intercept), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_Intercept), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Intercept') +
  labs(title="Model 1 - Intercept") +
  theme_bw()

#prior-posterior update plot for b:
m1p2 <- ggplot(Posterior_m1) +
  geom_density(aes(prior_b), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_Diagnosistd), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('b') +
  labs(title="Model 1 - b") +
  theme_bw()

#prior-posterior update plot for sigma:
m1p3 <- ggplot(Posterior_m1) +
  geom_density(aes(prior_sigma), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sigma), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Sigma') +
  labs(title="Model 1 - Sigma") +
  theme_bw()

grid1 <- grid.arrange(m1p1, m1p2, m1p3, ncol = 2)
ggsave("pp1.jpg", grid1)


```

###Prior-pposterior update plots for model 2
```{r}
#Sample the parameters of interest:
Posterior_m2 <- as_draws_df(MLU_m2)

#Plot the prior-posterior update plot for the b:
m2p1 <- ggplot(Posterior_m2) +
  geom_density(aes(prior_b_Diagnosisasd), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_Diagnosisasd), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Intercept') +
  labs(title="Model 2 - Intercept") +
  theme_bw()
  
#Plot the prior-posterior update plot for b with interaction:
m2p2 <- ggplot(Posterior_m2) +
  geom_density(aes(`prior_b_Diagnosisasd:Visit`), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(`b_Diagnosisasd:Visit`), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('b') +
  labs(title="Model 2 - b interaction with visit ASD") +
  theme_bw()

m2p3 <- ggplot(Posterior_m2) +
  geom_density(aes(`prior_b_Diagnosistd:Visit`), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(`b_Diagnosistd:Visit`), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('b') +
  labs(title="Model 2 - b interaction with visit TD") +
  theme_bw()

#Plot the prior-posterior update plot for sigma:
m2p4 <- ggplot(Posterior_m2) +
  geom_density(aes(prior_sigma), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sigma), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Sigma') +
  labs(title="Model 2 - Sigma") +
  theme_bw()

grid2 <- grid.arrange(m2p1, m2p2, m2p3, m2p4, ncol = 2)
ggsave("pp2.jpg", grid2)

```


### Prior-posterior update plots for model 3
```{r}
#Sample the parameters of interest:
Posterior_m3 <- as_draws_df(MLU_m3_1)

#Plot the prior-posterior update plot for b:
pl1 <- ggplot(Posterior_m3) +
  geom_density(aes(prior_b_Diagnosisasd), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_Diagnosisasd), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Intercept') +
  labs(title="Model 3 - Intercept") +
  theme_bw()

#Plot the prior-posterior update plot for sigma:
pl2 <- ggplot(Posterior_m3) +
  geom_density(aes(prior_sigma), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sigma), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Sigma') +
  labs(title="Model 3 - Sigma") +
  theme_bw()

#Plot the prior-posterior update plot for sd of intercepts and slopes:
pl3 <- ggplot(Posterior_m3) +
  geom_density(aes(sd_ID__Intercept), fill="#FC4E07", color="black",alpha=0.3) + 
  geom_density(aes(sd_ID__Visit), fill="#228B22", color="black",alpha=0.4) + 
  geom_density(aes(prior_sd_ID__Visit), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(prior_sd_ID__Intercept), fill="red", color="black",alpha=0.6) +
  xlab('sd') +
  labs(title="Model 3 - Intercepts and slopes") +
  xlim(0, 0.7) +
  theme_bw()

#Plot the prior-posterior update plot for the correlation between varying intercepts and slopes:
pl4 <- ggplot(Posterior_m3) +
  geom_density(aes(prior_cor_ID), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(cor_ID__Intercept__Visit), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('cor') +
  labs(title="Model 3 - correlation between varying intercepts and slopes") +
  theme_bw()

#Plot the prior-posterior update plot for slope asd:
pl5 <- ggplot(Posterior_m3) +
  geom_density(aes(Posterior_m3$'prior_b_Diagnosisasd:Visit'), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(Posterior_m3$'b_Diagnosisasd:Visit'), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Varying slopes - ASD")+
  xlab("DiagnosisASD:Visit") +
  theme_bw()

# For the TD
pl6 <- ggplot(Posterior_m3) +
  geom_density(aes(Posterior_m3$'prior_b_Diagnosistd:Visit'), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(Posterior_m3$'b_Diagnosistd:Visit'), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Varying slopes - TD")+
  xlab("DiagnosisTD:Visit") +
  theme_bw()

m3_plots <- grid.arrange(pl1, pl2, pl3, pl4, pl5, pl6, ncol = 3, top = "Prior-posterior update plots")
ggsave("m3_prior_posterior.jpg", m3_plots)


```


### Conditional effects
```{r}
# plot(conditional_effects(MLU_m1),points = T)
# plot(conditional_effects(MLU_m2),points = T)
# plot(conditional_effects(MLU_m3),points = T) 
```


### Traceplots
```{r}
# plot(MLU_m1, main = "Model 1")
# plot(MLU_m2, main = "Model 2")
# plot(MLU_m3, main = "Model 3")
```

### Model summary
```{r}
summary(MLU_m1)
summary(MLU_m2)
summary(MLU_m3)
```




## Parameter recovery/Individual level estimated (This does not work)
The ability of the model  to recover the true underlying  parameter values
We then want to extract how the model is assessing the individual datapoints i.e., the different slopes and intercepts for each individual child:

(Each dot = Intercept for individual child)

### Divergence 
```{r}

mcmc_parcoord(
  MLU_m3_1,
  pars = vars(matches('^b')),
  size = .25, 
  alpha = .01,
  np = nuts_params(MLU_m3),
  np_style = parcoord_style_np(
    div_color = "#ff5500",
    div_size = 1,
    div_alpha = .1
  )
) +
  guides(x = guide_axis(n.dodge = 2)) +
  theme(
    axis.text.x = element_text(size = 6),
    panel.grid.major.x = element_line(color = '#00AAFF80', size = .1)
  )

mcmc_parcoord(
  MLU_m2,
  pars = vars(matches('^b')),
  size = .25, 
  alpha = .01,
  np = nuts_params(MLU_m2),  # without this div trans won't be highlighted
  np_style = parcoord_style_np(
    div_color = "#ff5500",
    div_size = 1,
    div_alpha = .1
  )
) +
  guides(x = guide_axis(n.dodge = 2)) +
  theme(
    axis.text.x = element_text(size = 6),
    panel.grid.major.x = element_line(color = '#00AAFF80', size = .1)
  )

mcmc_parcoord(
  MLU_m1,
  pars = vars(matches('^b')),
  size = .25, 
  alpha = .01,
  np = nuts_params(MLU_m1),  # without this div trans won't be highlighted
  np_style = parcoord_style_np(
    div_color = "#ff5500",
    div_size = 1,
    div_alpha = .1
  )
) +
  guides(x = guide_axis(n.dodge = 2)) +
  theme(
    axis.text.x = element_text(size = 6),
    panel.grid.major.x = element_line(color = '#00AAFF80', size = .1)
  )


```

### Model outputs - Rhat, bulks and tails
```{r}
summary(MLU_m1)
summary(MLU_m2)
summary(MLU_m3)
```
Model 3 definitely seems to work the best

### Model comparison
```{r}
# Cross-validation
set.seed(3006)

kfold1 <- brms::kfold(MLU_m1,folds="stratified",group="Diagnosis",K=5,save_fits = TRUE)

# Define a loss function
rmse <- function(y,yrep){
  yrep_mean <- colMeans(yrep)
  sqrt(mean(yrep_mean-y)^2)
}

# predict responses and evaluate the loss
kfp <- kfold_predict(kfold1)
kfp_test <- kfold_predict(kfold1)


```

```{r}
kfp
kfp_test
```


We are going with model 3, best rhat, tails and bulks

### Cross validation with loo
```{r}
# cross validation
pacman::p_load("loo")

loo_jingle <- loo(MLU_m1)     
loo_bell <- loo(MLU_m2)
#loowhy <- loo_moment_match(MLU_m3, looc)
loo_rock <- loo(MLU_m3_1)

loo::loo_compare(loo_jingle,loo_bell, loo_rock)
loo::loo_model_weights(loo_jingle,loo_bell, loo_rock)
# should show that third model is best
```

```{r}
dim(log_lik(MLU_m1))
dim(log_lik(MLU_m2))
dim(log_lik(MLU_m3_1))
```


### Power analysis
We’d like to make sure we plan on collecting enough data to do a good job showing that. A power analysis will help
What our power analysis will help us determine is how many cases we’ll need to achieve a predetermined level of power
```{r}
# Set a new set
set.seed(411)

# Simulate new data based on the new seed
n_new <- 70
Visit_new <- 6
d_new <- tibble(expand.grid(
  ID=seq(n_new),
  Diagnosis=(c('asd','td')),
  Visit=seq(Visit_new),
  IndivdualIntercept = as.numeric(0),
  IndividualSlope = as.numeric(0),
  MLU = as.numeric(0)))

d_new <- d_new %>% 
  mutate(ID=ifelse(Diagnosis=="asd",ID+(n*2),ID))

for (i in seq(d_new$ID)){
    d_new$IndivdualIntercept[d_new$ID == i & d_new$Diagnosis == "asd"] <- rnorm(1,mu_asd,sigma_asd)
    d_new$IndivdualIntercept[d_new$ID == i & d_new$Diagnosis == "td"] <- rnorm(1,mu_td,sigma_td)
    d_new$IndividualSlope[d_new$ID == i & d_new$Diagnosis == "asd"] <- rnorm(1,mu_visit_asd,sigma_visit_asd)
    d_new$IndividualSlope[d_new$ID == i & d_new$Diagnosis == "td"] <- rnorm(1,mu_visit_td,sigma_visit_td)
}

for (i in seq(nrow(d_new))){
  d_new$MLU[i] <- exp(rnorm(1,d_new$IndivdualIntercept[i]+d_new$IndividualSlope[i]*(d_new$Visit[i]-1),error))
}

# Update our first fit
updated_fit1 <- 
  update(MLU_m1,
         newdata=d_new,
         seed = 2)
updated_fit2 <- 
  update(MLU_m2,
         newdata=d_new,
         seed = 2)
updated_fit3 <- 
  update(MLU_m3_1,
         newdata=d_new,
         seed = 2)



```

```{r}
fixef(updated_fit1)
fixef(updated_fit2)
fixef(updated_fit3)

```

```{r}
# Making a custom model-fitting function 
sim_d <- function(seed,n){
  set.seed(seed)
  
  d_sim <- tibble(expand.grid(
    ID=seq(n),
    Diagnosis=(c('asd','td')),
    Visit=seq(Visit),
    IndivdualIntercept = NA,
    IndividualSlope = NA,
    MLU = NA))

  d_sim <- d_sim %>% 
    mutate(ID=ifelse(Diagnosis=="asd",ID+(n*2),ID))
  
  
  for (i in seq(d_sim$ID)){
    d_sim$IndivdualIntercept[d_sim$ID == i & d_sim$Diagnosis == "asd"]<-
      rnorm(1,mu_asd,sigma_asd)
    d_sim$IndivdualIntercept[d_sim$ID == i & d_sim$Diagnosis == "td"] <-
      rnorm(1,mu_td,sigma_td)
    d_sim$IndividualSlope[d_sim$ID == i & d_sim$Diagnosis == "asd"] <-
      rnorm(1,mu_visit_asd,sigma_visit_asd)
    d_sim$IndividualSlope[d_sim$ID == i & d_sim$Diagnosis == "td"] <-
      rnorm(1,mu_visit_td,sigma_visit_td)
    }
  
  for (i in seq(nrow(d_sim))){
    d_sim$MLU[i] <- exp(rnorm(1,d_sim$IndivdualIntercept[i]+d$IndividualSlope[i]*(d$Visit[i]-1),error))
  }
}

```


```{r}
# how many simulations

n_sim <- 10

# tracks time
t1 <- Sys.time()

# creating a tibble of the simulations
s3 <-
  tibble(seed = 1:n_sim) %>%
  mutate(d = purrr::map(seed, sim_d, n = 70)) %>%
  mutate(fit = purrr::map2(d, seed, ~update(MLU_m3, newdata = .x, seed = .y,iter=1000)))
         
t2 <- Sys.time()


```


```{r}
parameters3 <-
  s3 %>%
  mutate(Diagnosis = map(fit, ~ fixef(.) %>%
                           data.frame() %>%
                           rownames_to_column("parameter"))) %>%
  unnest(Diagnosis)

parameters3 %>%
  select(-d, -fit) %>%
  filter(parameter == "Diagnosisasd") %>%
  head()


```


```{r}
parameters_plot <- parameters3 %>% 
  ggplot(aes(x = seed, y = Estimate, ymin = Q2.5, ymax = Q97.5,color=parameter)) +
  geom_hline(yintercept = c(0, .5), color = "white") +
  geom_pointrange(fatten = 1/2) +
  labs(x = "seed (i.e., simulation index)",
       y = expression(beta[1])) +
  ylim(0.05, 0.4)
parameters_plot

ggsave("parameters.jpg", parameters_plot)

```


```{r}
parameters3 %>% 
  filter(parameter == "Diagnosisasd") %>% 
  mutate(check = ifelse(Q2.5 > 0, 1, 0)) %>% 
  summarise(power = mean(check))

parameters3 %>% 
  filter(parameter == "Diagnosistd") %>% 
  mutate(check = ifelse(Q2.5 > 0, 1, 0)) %>% 
  summarise(power = mean(check))

```


```{r}
s3 %>% 
  mutate(rhat = map(fit, rhat)) %>% 
  unnest(rhat) %>% 
  ggplot(aes(x = rhat)) +
           geom_histogram(bins = 500) + xlim(0.999,1.016)

ggsave("rhat.jpg")
```



# Part 2 - Strong in the Bayesian ken, you are now ready to analyse the actual data



- Describe individual differences in linguistic development: do all kids follow the same path? Are all kids reflected by the general trend for their group?

- Include additional predictors in your model of language development (N.B. not other indexes of child language: types and tokens, that'd be cheating). Identify the best model, by conceptual reasoning, model comparison or a mix. Report the model you choose (and name its competitors, if any) and discuss why it's the best model.

### Renaming data for simplicity
```{r}
df <- asd_data %>% 
 rename(ID=Child.ID)
df <- df %>% 
  rename(MLU=CHI_MLU)

head(df)

```


### Extracting infos about the study
- Describe your sample (n, age, gender, clinical and cognitive features of the two groups) and critically assess whether the groups (ASD and TD) are balanced. Briefly discuss whether the data is enough given the simulations in part 1.
```{r}
# Describing my sample
sum_gender <- df%>% 
  subset(Visit==1) %>% 
  filter(Gender=="M"|Gender=="F",Diagnosis=="ASD"|Diagnosis=="TD") %>% 
  group_by(Gender,Diagnosis) %>% 
  summarise(n=length(unique(ID)),Average_Age = mean(Age,na.rm=T), mean_MLU = mean(MLU,na.rm=T),sd_MLU=sd(MLU,na.rm=T))

sum_diag <- df%>% 
  subset(Visit==1) %>% 
  group_by(Diagnosis) %>% 
  summarise(n=length(unique(ID)),Average_Age = mean(Age,na.rm=T), mean_MLU = mean(MLU,na.rm=T),sd_MLU=sd(MLU,na.rm=T))

#n_start, n_end
sum_gender
sum_diag
```


```{r}
df <- filter(df, MLU > 0)

```


###Plotting linguistic development
- Describe linguistic development (in terms of MLU over time) in TD and ASD children (as a function of group). Discuss the difference (if any) between the two groups.
```{r}
ggplot(df) +
 aes(x = MLU, color = Diagnosis) +
 geom_density(adjust = 1L) +
 scale_fill_hue(direction = 1) +
 theme_minimal() +
  labs(title="Distrubtion plot of the empircal data")

ggsave("empdata.jpg")

```

###Setting up a comparison of the data
```{r}
sim_gg <- ggplot(d, aes(Visit, MLU, col = Diagnosis, group = ID)) + 
theme_bw() + 
geom_point() +
geom_line(alpha = 0.3) +
ggtitle("Simulated data")

rea_gg <- ggplot(df, aes(Visit, MLU, col = Diagnosis, group = ID)) + 
theme_bw() + 
geom_point() +
geom_line(alpha = 0.3) +
ggtitle("Real data")

sim_real <- grid.arrange(sim_gg, rea_gg, nrow = 2)
ggsave("Simulation_plot.jpeg", sim_real)


```


## Modeling the data

### Defining the model formula
```{r}
MLU_f_3 <- MLU ~  0 + Diagnosis + Diagnosis:Visit + (1+Visit|ID)
```


### Defining the priors
```{r}
real_p3 <- c(
  prior(normal(0.41,0.8),class=b,coef="DiagnosisASD"),
  prior(normal(0.41,0.5),class=b,coef="DiagnosisTD"),
  prior(normal(0,0.2),class=b,coef="DiagnosisASD:Visit"),
  prior(normal(0,0.13),class=b,coef="DiagnosisTD:Visit"),
  prior(normal(0,0.4),class=sd,coef=Intercept,group=ID),
  prior(normal(0,0.3),class=sd,coef=Visit,group=ID),
  prior(normal(1,0.5),class=sigma),
  prior(lkj(1),class="cor"))


```


### Running the model - only with priors
```{r warning = FALSE}
real_m3_prior <- 
  brms::brm(
    MLU_f_3,
    data = df,
    prior = real_p3,
    family = lognormal,
    sample_prior="only",
    backend = "cmdstanr",
    file = "emp_m3_1",
    iter = 4000, 
    warmup = 1000,
    chains = 2,
    cores = 2,
    control = list(
      adapt_delta = 0.99,
      max_treedepth = 20
    )
  )

```


### 
```{r}
pp_real <- pp_check(real_m3_prior, ndraws = 100) + labs(title = "Real data - prior") + xlim(0, 20)
pp_real

```


Running the model with the real data:
```{r}
real_m3 <-
  brm(
    MLU_f_3,
    data = df,
    family = lognormal,
    prior = real_p3,
    file = "emp_m3_2",
    sample_prior = T,
    iter = 4000, 
    warmup = 1000,
    cores = 2,
    chains = 4,
    backend = "cmdstanr",
    threads = threading(4),
    control = list(
      adapt_delta = 0.99,
      max_treedepth = 15 ))
```


```{r}
ppos_real <- pp_check(real_m3, ndraws = 100) + labs(title = "Real data - posterior")
ppos_real

```


### Prior posterior update check
```{r}
#Sample the parameters of interest:
Pos_3 <- as_draws_df(real_m3)

#Plot the prior-posterior update plot for b:
p31 <- ggplot(Pos_3) +
  geom_density(aes(prior_b_DiagnosisASD), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_DiagnosisASD), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Intercept') +
  labs(title="Intercept") +
  theme_bw()

#Plot the prior-posterior update plot for sigma:
p32 <- ggplot(Pos_3) +
  geom_density(aes(prior_sigma), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sigma), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('Sigma') +
  labs(title="Sigma") +
  theme_bw()

#Plot the prior-posterior update plot for sd of intercepts and slopes:
p33 <- ggplot(Pos_3) +
  geom_density(aes(sd_ID__Intercept), fill="#FC4E07", color="black",alpha=0.3) + 
  geom_density(aes(sd_ID__Visit), fill="#228B22", color="black",alpha=0.4) + 
  geom_density(aes(prior_sd_ID__Visit), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(prior_sd_ID__Intercept), fill="red", color="black",alpha=0.6) +
  xlab('sd') +
  labs(title="Intercepts and slopes") +
  theme_bw()

#Plot the prior-posterior update plot for slope asd:
p34 <- ggplot(Pos_3) +
  geom_density(aes(Pos_3$'prior_b_DiagnosisASD:Visit'), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(Pos_3$'b_DiagnosisASD:Visit'), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Varying slopes - ASD")+
  xlab("ASD:Visit") +
  theme_bw()

# For the TD
p35 <- ggplot(Pos_3) +
  geom_density(aes(Pos_3$'prior_b_DiagnosisTD:Visit'), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(Pos_3$'b_DiagnosisTD:Visit'), fill="#FC4E07", color="black",alpha=0.6) + 
  labs(title = "Varying slopes - TD")+
  xlab("TD:Visit") +
  theme_bw()

#Plot the prior-posterior update plot for the correlation between varying intercepts and slopes:
p36 <- ggplot(Pos_3) +
  geom_density(aes(prior_cor_ID), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(cor_ID__Intercept__Visit), fill="#FC4E07", color="black",alpha=0.6) + 
  xlab('cor') + 
  labs(title="Cor - Varying int & slop") +
  theme_bw()

grid3 <- grid.arrange(p31, p32, p33, p34, p35, p36, nrow = 2)
ggsave("gridpart3.jpg", grid3)
```



```{r}
summary(real_m3)
```

###Traceplot
```{r}

plot(real_m3, main = "Model 3")
```


### Hypothesis testing
```{r}
hypothesis(real_m3, "DiagnosisASD:Visit<DiagnosisTD:Visit")
hypothesis(real_m3, "Visit>0.03", group = "ID", scope="coef")

hypothesis(real_m3, "DiagnosisASD > DiagnosisTD")

```



### Priors for loop
```{r}
ASD_priors_real <- c(
  prior(normal(0.41,0.8),class=b,coef="DiagnosisASD"),
  #prior(normal(0.41,0.5),class=b,coef="DiagnosisTD"),
  #prior(normal(0,0.2),class=b,coef="DiagnosisASD:Visit"),
  #prior(normal(0,0.13),class=b,coef="DiagnosisTD:Visit"),
  prior(normal(0,0.4),class=sd,coef=Intercept,group=ID),
  prior(normal(0,0.3),class=sd,coef=Visit,group=ID),
  prior(normal(1,0.5),class=sigma),
  prior(lkj(1),class="cor"))
```


### Sensitivity check
```{r}
ASD_prior_SD_real <- seq(0.01, 0.20, length.out = 20)


#create empty sets to store output of the loop for ASD:
real_posterior_prediction_ASD <- c()
real_posterior_prediction_ASD_lci <- c()
real_posterior_prediction_ASD_uci <- c()

#Making all the priors we want to check (aka just changing the sd)
real_sd_priors <- c(
  prior(normal(0, 0.01), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.02), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.03), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.04), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.05), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.06), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.07), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.08), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.09), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.10), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.11), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.12), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.13), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.14), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.15), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.16), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.17), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.18), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.19), class = b, coef= "DiagnosisASD:Visit"),
  prior(normal(0, 0.20), class = b, coef= "DiagnosisASD:Visit")
)

#loop through making priors with different sd
for (i in seq(1, 20)) {
  ASD_priors_real[5,] <- real_sd_priors[i,]
  real_model_for_loop_ASD <- brm(
    MLU_f_3,
    data= df,
    family = lognormal,
    prior = ASD_priors_real,
    sample_prior = T,
    iter = 2000,
    warmup = 1000,
    backend = "cmdstanr",
    threads = threading(2),
    cores = 2,
    chains = 2,
    control = list(adapt_delta = 0.99, max_treedepth = 20)
  )
    
  Model_for_loop_samp_real_ASD <- as_draws_df(real_model_for_loop_ASD)
  #posterior_predictions <- spread_draws(model_for_loop, b_DiagASD:Visit) #slope, so b_DiagASD:Visit
  real_posterior_predictions_ASD <- Model_for_loop_samp_real_ASD[,4]
  real_posterior_prediction_ASD[i] <- median(real_posterior_predictions_ASD$'b_DiagnosisASD:Visit')
  real_posterior_prediction_ASD_lci[i] <- quantile(real_posterior_predictions_ASD$'b_DiagnosisASD:Visit', prob = 0.025) #lower boundy for 95% interval
  real_posterior_prediction_ASD_uci[i] <- quantile(real_posterior_predictions_ASD$'b_DiagnosisASD:Visit', prob = 0.975) #upper boundry for 95% interval
}

#view(Model_for_loop_samp_real)

#Making dataframe from values from loop
real_sensitivity_check_ASD <- data.frame(ASD_prior_SD_real, real_posterior_prediction_ASD, real_posterior_prediction_ASD_lci, real_posterior_prediction_ASD_uci) 

#visualizing the sensitivity plot
real_rubostness_check_ASD <- ggplot(data=real_sensitivity_check_ASD, aes(x=ASD_prior_SD_real, y=real_posterior_prediction_ASD)) +
  geom_point(size = 3) +
  geom_pointrange(ymin = real_posterior_prediction_ASD_lci, ymax = real_posterior_prediction_ASD_uci) + #pointrange is 95% interval (vertical lines for each dot)
  ylim(0.05, 0.25) + #range for the slope (y-aksis range)
  labs(x="Standard Deviation of Slope Prior", 
       y="Posterior Estimate for Slope", 
       title="Sensitivity analysis for multi-level model ASD") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5, size = 15),
        axis.title.x = element_text(size = 13),
        axis.text.y = element_text(size = 12),
        axis.text.x = element_text(size = 12),
        axis.title.y = element_text(size = 13))




ggsave("rubostness_check_ASD.jpg", plot=real_rubostness_check_ASD)
real_rubostness_check_ASD



```


```{r}
TD_priors_real <- c(
  #prior(normal(0.41,0.8),class=b,coef="DiagnosisASD"),
  prior(normal(0.41,0.5),class=b,coef="DiagnosisTD"),
  #prior(normal(0,0.2),class=b,coef="DiagnosisASD:Visit"),
  #prior(normal(0,0.13),class=b,coef="DiagnosisTD:Visit"),
  prior(normal(0,0.4),class=sd,coef=Intercept,group=ID),
  prior(normal(0,0.3),class=sd,coef=Visit,group=ID),
  prior(normal(1,0.5),class=sigma),
  prior(lkj(1),class="cor"))
```


### Sensitivity check TD
```{r}
TD_prior_SD_real <- seq(0.01, 0.20, length.out = 20)


#create empty sets to store output of the loop for ASD:
real_posterior_prediction_TD <- c()
real_posterior_prediction_TD_lci <- c()
real_posterior_prediction_TD_uci <- c()

#Making all the priors we want to check (aka just changing the sd)
real_sd_priors <- c(
  prior(normal(0, 0.01), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.02), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.03), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.04), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.05), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.06), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.07), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.08), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.09), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.10), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.11), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.12), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.13), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.14), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.15), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.16), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.17), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.18), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.19), class = b, coef= "DiagnosisTD:Visit"),
  prior(normal(0, 0.20), class = b, coef= "DiagnosisTD:Visit")
)

#loop through making priors with different sd
for (i in seq(1, 20)) {
  TD_priors_real[5,] <- real_sd_priors[i,]
  real_model_for_loop_TD <- brm(
    MLU_f_3,
    data= df,
    family = lognormal,
    prior = TD_priors_real,
    sample_prior = T,
    iter = 2000,
    warmup = 1000,
    backend = "cmdstanr",
    threads = threading(2),
    cores = 2,
    chains = 2,
    control = list(adapt_delta = 0.99, max_treedepth = 20)
  )
    
  Model_for_loop_samp_real_TD <- as_draws_df(real_model_for_loop_TD)
  #posterior_predictions <- spread_draws(model_for_loop, b_DiagASD:Visit) #slope, so b_DiagASD:Visit
  real_posterior_predictions_TD <- Model_for_loop_samp_real_TD[,4]
  real_posterior_prediction_TD[i] <- median(real_posterior_predictions_TD$'b_DiagnosisTD:Visit')
  real_posterior_prediction_TD_lci[i] <- quantile(real_posterior_predictions_TD$'b_DiagnosisTD:Visit', prob = 0.025) #lower boundy for 95% interval
  real_posterior_prediction_TD_uci[i] <- quantile(real_posterior_predictions_TD$'b_DiagnosisTD:Visit', prob = 0.975) #upper boundry for 95% interval
}

#view(Model_for_loop_samp_real)

#Making dataframe from values from loop
real_sensitivity_check_TD <- data.frame(TD_prior_SD_real, real_posterior_prediction_TD, real_posterior_prediction_TD_lci, real_posterior_prediction_TD_uci) 

#visualizing the sensitivity plot
real_rubostness_check_td <- ggplot(data=real_sensitivity_check_TD, aes(x=TD_prior_SD_real, y=real_posterior_prediction_TD)) +
  geom_point(size = 3) +
  geom_pointrange(ymin = real_posterior_prediction_TD_lci, ymax = real_posterior_prediction_TD_uci) + #pointrange is 95% interval (vertical lines for each dot)
  ylim(0.05, 0.25) + #range for the slope (y-aksis range)
  labs(x="Standard Deviation of Slope Prior", 
       y="Posterior Estimate for Slope", 
       title="Sensitivity analysis for multi-level model TD") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5, size = 15),
        axis.title.x = element_text(size = 13),
        axis.text.y = element_text(size = 12),
        axis.text.x = element_text(size = 12),
        axis.title.y = element_text(size = 13))




ggsave("rubostness_check_td.jpg", plot=real_rubostness_check_td)
real_rubostness_check_td



```





